{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet: time series data exploration\n",
    "Data and examples from https://keras.io/examples/timeseries/timeseries_weather_forecasting/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data \n",
    "from zipfile import ZipFile\n",
    "\n",
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall()\n",
    "csv_path = \"jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the column names, their value formats, and their description.\n",
    "\n",
    "| Index |     Features    |        Format       |                                                                                                      Description                                                                                                     |\n",
    "|:-----:|:---------------:|:-------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| 1     | Date Time       | 01.01.2009 00:10:00 | Date-time reference                                                                                                                                                                                                  |\n",
    "| 2     | p (mbar)        | 996.52              | The pascal SI derived unit of pressure used to quantify internal  pressure. Meteorological reports typically state atmospheric pressure in  millibars.                                                               |\n",
    "| 3     | T (degC)        | -8.02               | Temperature in Celsius                                                                                                                                                                                               |\n",
    "| 4     | Tpot (K)        | 265.4               | Temperature in Kelvin                                                                                                                                                                                                |\n",
    "| 5     | Tdew (degC)     | -8.9                | Temperature in Celsius relative to humidity. Dew Point is a measure  of the absolute amount of water in the air, the DP is the temperature at  which the air cannot hold all the moisture in it and water condenses. |\n",
    "| 6     | rh (%)          | 93.3                | Relative Humidity is a measure of how saturated the air is with  water vapor, the %RH determines the amount of water contained within  collection objects.                                                           |\n",
    "| 7     | VPmax (mbar)    | 3.33                | Saturation vapor pressure                                                                                                                                                                                            |\n",
    "| 8     | VPact (mbar)    | 3.11                | Vapor pressure                                                                                                                                                                                                       |\n",
    "| 9     | VPdef (mbar)    | 0.22                | Vapor pressure deficit                                                                                                                                                                                               |\n",
    "| 10    | sh (g/kg)       | 1.94                | Specific humidity                                                                                                                                                                                                    |\n",
    "| 11    | H2OC (mmol/mol) | 3.12                | Water vapor concentration                                                                                                                                                                                            |\n",
    "| 12    | rho (g/m ** 3)  | 1307.75             | Airtight                                                                                                                                                                                                             |\n",
    "| 13    | wv (m/s)        | 1.03                | Wind speed                                                                                                                                                                                                           |\n",
    "| 14    | max. wv (m/s)   | 1.75                | Maximum wind speed                                                                                                                                                                                                   |\n",
    "| 15    | wd (deg)        | 152.3               | Wind direction in degrees                                                                                                                                                                                            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the raw data \n",
    "titles = [\n",
    "    \"Pressure\",\n",
    "    \"Temperature\",\n",
    "    \"Temperature in Kelvin\",\n",
    "    \"Temperature (dew point)\",\n",
    "    \"Relative Humidity\",\n",
    "    \"Saturation vapor pressure\",\n",
    "    \"Vapor pressure\",\n",
    "    \"Vapor pressure deficit\",\n",
    "    \"Specific humidity\",\n",
    "    \"Water vapor concentration\",\n",
    "    \"Airtight\",\n",
    "    \"Wind speed\",\n",
    "    \"Maximum wind speed\",\n",
    "    \"Wind direction in degrees\",\n",
    "]\n",
    "\n",
    "feature_keys = [\n",
    "    \"p (mbar)\",\n",
    "    \"T (degC)\",\n",
    "    \"Tpot (K)\",\n",
    "    \"Tdew (degC)\",\n",
    "    \"rh (%)\",\n",
    "    \"VPmax (mbar)\",\n",
    "    \"VPact (mbar)\",\n",
    "    \"VPdef (mbar)\",\n",
    "    \"sh (g/kg)\",\n",
    "    \"H2OC (mmol/mol)\",\n",
    "    \"rho (g/m**3)\",\n",
    "    \"wv (m/s)\",\n",
    "    \"max. wv (m/s)\",\n",
    "    \"wd (deg)\",\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "date_time_key = \"Date Time\"\n",
    "\n",
    "\n",
    "def show_raw_visualization(data):\n",
    "    time_data = data[date_time_key]\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=7, ncols=2, figsize=(15, 20), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "    )\n",
    "    for i in range(len(feature_keys)):\n",
    "        key = feature_keys[i]\n",
    "        c = colors[i % (len(colors))]\n",
    "        t_data = data[key]\n",
    "        t_data.index = time_data\n",
    "        t_data.head()\n",
    "        ax = t_data.plot(\n",
    "            ax=axes[i // 2, i % 2],\n",
    "            color=c,\n",
    "            title=\"{} - {}\".format(titles[i], key),\n",
    "            rot=25,\n",
    "        )\n",
    "        ax.legend([titles[i]])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "show_raw_visualization(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how data look like \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date time as the index \n",
    "df = df.set_index(['Date Time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show summary of the data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean bad values \n",
    "df = df[df['wv (m/s)'] != -9999.0]\n",
    "df = df[df['max. wv (m/s)'] != -9999.0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the data after cleaning\n",
    "df = df.reset_index() # reset the index to use the visualisation function \n",
    "show_raw_visualization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see linear correlation between the variables \n",
    "df = df.set_index(['Date Time'])\n",
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise correlation matrix (linear/Pearson correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='bwr', vmax=1.0, vmin=-1.0, center=0,\n",
    "                 square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, \n",
    "                 annot=True, fmt=\".1f\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a reduced dataset to work with less variables for now\n",
    "reduced_df = df[['p (mbar)', 'T (degC)', 'rh (%)', 'H2OC (mmol/mol)', 'wv (m/s)']]\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns \n",
    "reduced_df.columns = ['Pressure', 'Temperature','RelativeHumidity', 'WaterConcentration', 'WindSpeed']\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation. There should be less redundancy this time. \n",
    "corr = reduced_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='bwr', vmax=1.0, vmin=-1.0, center=0,\n",
    "                 square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, \n",
    "                 annot=True, fmt=\".1f\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Nonlinear Correlation with Mutual Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression as mi_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define independent variables in the reduced dataset \n",
    "indep_vars = ['Pressure','RelativeHumidity', 'WaterConcentration', 'WindSpeed'] # set independent vars\n",
    "dep_vars = reduced_df.columns.difference(indep_vars).tolist() # set dependent vars\n",
    "print(indep_vars)\n",
    "print(dep_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mutual information (nonlinear correlation) between independent and dependent variables \n",
    "reduceddf_mi = pd.DataFrame([mi_reg(reduced_df[indep_vars], reduced_df[dep_var]) for dep_var in dep_vars], index = dep_vars, columns = indep_vars).apply(lambda x: x / x.max(), axis = 1)\n",
    "reduceddf_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mutual information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(8,3))\n",
    "\n",
    "ax = sns.heatmap(reduceddf_mi, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot=True, fmt=\".1f\", cmap='turbo', vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try modeling the temperature with random forest regression \n",
    "### Since the dataset is large, we will resample it first to work with a smaller dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the \"Date Time\" so that it is understood by Pandas. Then we make it as the index for easy handling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = reduced_df.reset_index()\n",
    "reduced_df['Date Time'] = pd.to_datetime(reduced_df['Date Time'], dayfirst=True)\n",
    "reduced_df = reduced_df.set_index(['Date Time'])\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample from 10-min cadence to 1-hour cadence using hourly mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data using hourly mean \n",
    "reduced_df = reduced_df.resample('1h').mean().interpolate()\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['Pressure','RelativeHumidity', 'WaterConcentration','WindSpeed']\n",
    "output_target = ['Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(input_features), 2, figsize=(12, 8))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "i = 0\n",
    "for col in input_features:\n",
    "    if i < len(input_features):\n",
    "        ax[i,0].plot(reduced_df[col], label=col)\n",
    "        ax[i,0].legend(loc='upper right',bbox_to_anchor=(1.0, 1.0))\n",
    "        i += 1 \n",
    "    \n",
    "j = 0\n",
    "for col in output_target:\n",
    "    if j < len(output_target):\n",
    "        ax[j,1].plot(reduced_df[col], label=col)\n",
    "        ax[j,1].legend(loc='upper right',bbox_to_anchor=(1.0, 1.0))\n",
    "        j += 1\n",
    "    \n",
    "\n",
    "ax[0,0].set_title('Input features')\n",
    "\n",
    "ax[0,1].set_title('Output targets')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data to train:validation:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column order \n",
    "reduced_df = reduced_df[['Pressure','RelativeHumidity', 'WaterConcentration','WindSpeed','Temperature']]\n",
    "\n",
    "# define training data from 2009 to end of 2012 (5 years)\n",
    "reduced_df_train = reduced_df[datetime(2009,1,1,0,0,0):datetime(2012,12,31,23,0,0)]\n",
    "\n",
    "# define validation data in 2013 \n",
    "reduced_df_val = reduced_df[datetime(2013,1,1,0,0,0):datetime(2013,12,31,23,0,0)]\n",
    "\n",
    "# define test data in 2014 \n",
    "reduced_df_test = reduced_df[datetime(2014,1,1,0,0,0):datetime(2014,12,31,23,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain scaling from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale the data frame\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## Obtain scaler based on the \"train\" data\n",
    "df_train_scaled = scaler.fit_transform(reduced_df_train)\n",
    "\n",
    "## Convert from dataframe to 2D array\n",
    "print('Train data: \\n',df_train_scaled)\n",
    "print(df_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the scaler for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "# save the scaler\n",
    "dump(scaler, open('Scaler_temperature-prediction.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the scaling obtained from the \"train\" data to \"validation\" and \"test\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_scaled = scaler.transform(reduced_df_val)\n",
    "df_test_scaled = scaler.transform(reduced_df_test)\n",
    "\n",
    "print('Validation data: \\n',df_val_scaled)\n",
    "print(df_val_scaled.shape)\n",
    "\n",
    "print('Test data: \\n',df_test_scaled)\n",
    "print(df_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X (independent variables) and y (dependent variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get input 'X'\n",
    "X_train = df_train_scaled[:,0:len(input_features)]\n",
    "\n",
    "print('X train = \\n',X_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "## Get output 'y'\n",
    "y_train = df_train_scaled[:,len(input_features):len(input_features)+len(output_target)]\n",
    "\n",
    "print('y train = \\n',y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val_scaled[:,0:len(input_features)]\n",
    "X_test = df_test_scaled[:,0:len(input_features)]\n",
    "\n",
    "y_val = df_val_scaled[:,len(input_features):len(input_features)+len(output_target)]\n",
    "y_test = df_test_scaled[:,len(input_features):len(input_features)+len(output_target)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model with Random Forest Regressor \n",
    "model.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Evaluate model performance on the train and validation data \n",
    "r2_train = model.score(X_train, y_train.ravel())\n",
    "r2_val = model.score(X_val, y_val.ravel())\n",
    "\n",
    "print(f\"model score on training data: {r2_train}\")\n",
    "print(f\"model score on validation data: {r2_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Random Forest, it is possible to obtain feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(importances)), importances[indices])\n",
    "ax.set_yticks(range(len(importances)))\n",
    "_ = ax.set_yticklabels(np.array(input_features)[indices])\n",
    "ax.set_title('Relative Importance for {} (training set)'.format(output_target))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly visualise the result on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, label='Real data')\n",
    "plt.plot(y_predict, label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale back the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the scaled 'X_test' and the 'y_predict' for using the inverse scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_scaled = np.concatenate((X_test,y_predict.reshape((len(y_predict), 1))), axis=1)\n",
    "print(predict_scaled.shape)\n",
    "print(predict_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inverse scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = scaler.inverse_transform(predict_scaled)\n",
    "print(predict)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataframe for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(predict)\n",
    "df_predict.columns = ['Pressure','RelativeHumidity', 'WaterConcentration','WindSpeed', 'Temperature']\n",
    "df_predict['time'] = reduced_df_test.index\n",
    "df_predict = df_predict.set_index(['time'])\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise model prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(reduced_df_test['Temperature'], label='True')\n",
    "ax1.plot(df_predict['Temperature'], label='Prediction')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Degree C')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4reg",
   "language": "python",
   "name": "ai4reg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
